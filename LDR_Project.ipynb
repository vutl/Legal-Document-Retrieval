{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9826425,
          "sourceType": "datasetVersion",
          "datasetId": 6026035
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "LDR Project",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vutl/Legal-Document-Retrieval/blob/main/LDR_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import kagglehub\n",
        "vutlol_legal_document_path = kagglehub.dataset_download('vutlol/legal-document')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "kAqzPnf0M_Il"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các thư viện cần thiết\n",
        "!pip --upgrade install rank_bm25 transformers torch pandas sentence-transformers tqdm"
      ],
      "metadata": {
        "trusted": true,
        "id": "PwtcnjL5M_Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import các thư viện\n",
        "import pandas as pd\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "from sentence_transformers import InputExample, losses, SentenceTransformer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import multiprocessing"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "-ZBUM7JAM_Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đường dẫn đến dữ liệu\n",
        "train_data_path = \"/kaggle/input/legal-document/train.csv\"\n",
        "corpus_path = \"/kaggle/input/legal-document/corpus.csv\"\n",
        "test_data_path = \"/kaggle/input/legal-document/public_test.csv\""
      ],
      "metadata": {
        "trusted": true,
        "id": "-aqH6jnbM_Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm tải dữ liệu Corpus\n",
        "def load_corpus(corpus_path):\n",
        "    corpus_df = pd.read_csv(corpus_path)\n",
        "    corpus_texts = corpus_df['text'].tolist()\n",
        "    corpus_ids = corpus_df['cid'].astype(str).tolist()\n",
        "    return corpus_texts, corpus_ids\n",
        "\n",
        "# Hàm tải dữ liệu huấn luyện\n",
        "def load_training_data(train_data):\n",
        "    training_examples = []\n",
        "    for index, row in train_data.iterrows():\n",
        "        question = row['question']\n",
        "        related_contexts = eval(row['context'])  # Dạng list chứa các đoạn văn bản liên quan\n",
        "        for context in related_contexts:\n",
        "            training_examples.append(InputExample(texts=[question, context]))\n",
        "    return training_examples"
      ],
      "metadata": {
        "trusted": true,
        "id": "bflmnf4uM_In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm fine-tune mô hình Halong Embedding\n",
        "def finetune_halong_embedding(train_data):\n",
        "    checkpoint_path = './checkpoint'  # Đường dẫn lưu mô hình\n",
        "\n",
        "    training_examples = load_training_data(train_data)\n",
        "    train_dataloader = DataLoader(training_examples, shuffle=True, batch_size=8)\n",
        "    model = SentenceTransformer(\"hiieu/halong_embedding\")\n",
        "\n",
        "    # Sử dụng MultipleNegativesRankingLoss cho việc huấn luyện\n",
        "    train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "    # Cài đặt thông số huấn luyện\n",
        "    num_epochs = 1\n",
        "    warmup_steps = int(0.1 * len(train_dataloader) * num_epochs)\n",
        "\n",
        "    model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "              epochs=num_epochs,\n",
        "              warmup_steps=warmup_steps,\n",
        "              output_path=checkpoint_path)\n",
        "\n",
        "    # Kiểm tra nếu checkpoint đã được lưu thành công\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(\"Checkpoint đã được lưu thành công tại:\", checkpoint_path)\n",
        "    else:\n",
        "        print(\"Lỗi: Không thể lưu checkpoint tại:\", checkpoint_path)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "cT1px6LPM_In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm BM25 truy xuất top_k tài liệu\n",
        "def bm25_retrieve(query, bm25_model, corpus_ids, top_k=10):\n",
        "    tokenized_query = query.split()\n",
        "    scores = bm25_model.get_scores(tokenized_query)\n",
        "    top_k_indices = np.argsort(scores)[::-1][:top_k]\n",
        "    top_k_docs = [(corpus_ids[idx], scores[idx]) for idx in top_k_indices]\n",
        "    return top_k_docs"
      ],
      "metadata": {
        "trusted": true,
        "id": "OzMjfQNlM_In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm tính toán MRR@10\n",
        "def calculate_mrr(retrieved_results, relevant_cids_list):\n",
        "    reciprocal_ranks = []\n",
        "    for query_retrieved_docs, relevant_cids in zip(retrieved_results, relevant_cids_list):\n",
        "        found = False\n",
        "        for rank, (doc_id, _) in enumerate(query_retrieved_docs, start=1):\n",
        "            if doc_id in relevant_cids:\n",
        "                reciprocal_ranks.append(1 / rank)\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            reciprocal_ranks.append(0)\n",
        "    return np.mean(reciprocal_ranks)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kAeVGt8fM_In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm xếp hạng lại với mô hình đã fine-tune\n",
        "def rerank_with_finetuned_embedding(query, doc_ids, corpus_texts, corpus_ids, model):\n",
        "    # Lấy văn bản của các tài liệu\n",
        "    documents = [corpus_texts[corpus_ids.index(doc_id)] for doc_id in doc_ids]\n",
        "\n",
        "    # Mã hóa câu hỏi và các văn bản\n",
        "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
        "    doc_embeddings = model.encode(documents, convert_to_tensor=True)\n",
        "\n",
        "    # Tính độ tương đồng cosine\n",
        "    similarities = F.cosine_similarity(query_embedding, doc_embeddings).cpu().numpy()\n",
        "\n",
        "    # Xếp hạng các tài liệu\n",
        "    sorted_indices = np.argsort(similarities)[::-1]\n",
        "    ranked_results = [(doc_ids[idx], similarities[idx]) for idx in sorted_indices]\n",
        "    return ranked_results"
      ],
      "metadata": {
        "trusted": true,
        "id": "A6WoN0KqM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bỏ wandb đi phiền vl\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "trusted": true,
        "id": "tBjTF1d4M_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm khởi tạo cho multiprocessing\n",
        "def init_bm25(tokenized_corpus_, corpus_ids_):\n",
        "    global bm25_model, corpus_ids\n",
        "    bm25_model = BM25Okapi(tokenized_corpus_)\n",
        "    corpus_ids = corpus_ids_"
      ],
      "metadata": {
        "trusted": true,
        "id": "b0TDquflM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm để trích xuất các số từ chuỗi trong cột 'cid'\n",
        "def parse_cid_list(cid_str):\n",
        "    # Sử dụng regex để tìm tất cả các số trong chuỗi\n",
        "    numbers = re.findall(r'\\d+', str(cid_str))\n",
        "    # Chuyển đổi các số thành chuỗi (vì corpus_ids là danh sách các chuỗi)\n",
        "    return [str(num) for num in numbers]"
      ],
      "metadata": {
        "trusted": true,
        "id": "nOGfwyYWM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dữ liệu\n",
        "corpus_texts, corpus_ids = load_corpus(corpus_path)\n",
        "train_df = pd.read_csv(train_data_path)\n",
        "\n",
        "# Chọn 50 câu hỏi từ tập train để thử nghiệm\n",
        "train_sample = train_df.sample(n=50, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Áp dụng hàm parse_cid_list vào cột 'cid' của mẫu\n",
        "train_relevant_cids = train_sample['cid'].apply(parse_cid_list).tolist()\n",
        "train_queries = train_sample['question'].tolist()"
      ],
      "metadata": {
        "trusted": true,
        "id": "-KEe_3LCM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model = SentenceTransformer(\"hiieu/halong_embedding\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "pK7qPM1VM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune lại mô hình Halong Embedding\n",
        "finetuned_model = finetune_halong_embedding(train_data_path)\n",
        "print(\"Đã fine-tune mô hình và lưu checkpoint.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MnTGcqXDM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuẩn bị dữ liệu cho BM25\n",
        "print(\"Đang chuẩn bị dữ liệu cho BM25...\")\n",
        "tokenized_corpus = [text.split() for text in corpus_texts]\n",
        "\n",
        "# Sử dụng multiprocessing để truy xuất BM25\n",
        "print(\"Đang thực hiện truy xuất BM25 cho 50 câu hỏi bằng multiprocessing...\")\n",
        "\n",
        "num_processes = multiprocessing.cpu_count()  # Số lượng tiến trình, bạn có thể điều chỉnh\n",
        "with multiprocessing.Pool(processes=num_processes, initializer=init_bm25, initargs=(tokenized_corpus, corpus_ids)) as pool:\n",
        "    retrieved_results = list(tqdm(pool.imap(bm25_retrieve, train_queries), total=len(train_queries)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "egjQXi7bM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính toán MRR@10 cho 50 câu hỏi với BM25\n",
        "mrr_bm25 = calculate_mrr(retrieved_results, train_relevant_cids)\n",
        "print(f\"Chỉ số MRR@10 cho 50 câu hỏi với BM25: {mrr_bm25:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "R1F_WSZrM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xếp hạng lại kết quả với mô hình đã fine-tune\n",
        "reranked_results = []\n",
        "print(\"Đang xếp hạng lại kết quả với mô hình đã fine-tune...\")\n",
        "for query, retrieved_docs in tqdm(zip(train_queries, retrieved_results), total=len(train_queries), desc=\"Reranking\"):\n",
        "    doc_ids = [doc_id for doc_id, _ in retrieved_docs]\n",
        "    reranked = rerank_with_finetuned_embedding(query, doc_ids, corpus_texts, corpus_ids, finetuned_model)\n",
        "    reranked_results.append(reranked)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-5oCznpRM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính toán MRR@10 cho 50 câu hỏi sau khi xếp hạng lại\n",
        "mrr_finetuned = calculate_mrr(reranked_results, train_relevant_cids)\n",
        "print(f\"Chỉ số MRR@10 cho 50 câu hỏi sau khi fine-tune: {mrr_finetuned:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "QPUtTKEJM_Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load dữ liệu\n",
        "# corpus_texts, corpus_ids = load_corpus(corpus_path)\n",
        "# train_df = pd.read_csv(train_data_path)\n",
        "# test_df = pd.read_csv(test_data_path)\n",
        "# queries = test_df['question'].tolist()\n",
        "# relevant_ids = test_df['qid'].tolist()  # Lấy danh sách id văn bản liên quan từ test\n",
        "\n",
        "# Phân tích tập dữ liệu Corpus\n",
        "# corpus_lengths = pd.Series([len(text.split()) for text in corpus_texts])\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.histplot(corpus_lengths[corpus_lengths < 1000], bins=50, kde=True)\n",
        "# plt.xlabel('Số lượng từ trong văn bản (giới hạn dưới 1000 từ)')\n",
        "# plt.ylabel('Tần suất')\n",
        "# plt.title('Phân bổ độ dài của các văn bản trong Corpus (Giới hạn dưới 1000 từ)')\n",
        "# plt.show()\n",
        "\n",
        "# # Phân tích tập dữ liệu Train\n",
        "# train_question_lengths = train_df['question'].apply(lambda x: len(x.split()))\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.histplot(train_question_lengths, bins=50, kde=True)\n",
        "# plt.xlabel('Số lượng từ trong câu hỏi')\n",
        "# plt.ylabel('Tần suất')\n",
        "# plt.title('Phân bổ độ dài của câu hỏi trong tập Train')\n",
        "# plt.show()\n",
        "\n",
        "# # Phân tích tập dữ liệu Test\n",
        "# test_question_lengths = test_df['question'].apply(lambda x: len(x.split()))\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.histplot(test_question_lengths, bins=50, kde=True)\n",
        "# plt.xlabel('Số lượng từ trong câu hỏi')\n",
        "# plt.ylabel('Tần suất')\n",
        "# plt.title('Phân bổ độ dài của câu hỏi trong tập Test')\n",
        "# plt.show()\n",
        "\n",
        "# # So sánh phân bổ độ dài câu hỏi giữa tập Train và Test\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.histplot(train_question_lengths, bins=50, kde=True, color='blue', label='Train')\n",
        "# sns.histplot(test_question_lengths, bins=50, kde=True, color='red', label='Test')\n",
        "# plt.xlabel('Số lượng từ trong câu hỏi')\n",
        "# plt.ylabel('Tần suất')\n",
        "# plt.title('So sánh phân bổ độ dài của câu hỏi giữa tập Train và Test')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# print(\"Nhận xét:\")\n",
        "# print(\"- Số lượng câu hỏi khác nhau trong tập Train và Test cho thấy tính đa dạng và tính tổng quát của mô hình.\")\n",
        "# print(\"- Nếu tập Test có nhiều câu hỏi dài hơn so với tập Train, mô hình có thể gặp khó khăn trong việc dự đoán chính xác vì chưa được huấn luyện đầy đủ với những câu hỏi dài như vậy.\")\n",
        "# print(\"- Phân bổ độ dài của câu hỏi trong hai tập dữ liệu có thể giúp đánh giá khả năng tổng quát hóa của mô hình.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZPb0RIq8M_Ip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}