{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9826425,"sourceType":"datasetVersion","datasetId":6026035}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vutranlong/ldr-project?scriptVersionId=206939851\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Import các thư viện cần thiết\n!pip install --upgrade rank_bm25 transformers torch pandas sentence-transformers tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import các thư viện\nimport pandas as pd\nfrom rank_bm25 import BM25Okapi\nimport numpy as np\nfrom sentence_transformers import InputExample, losses, SentenceTransformer\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nimport os\nfrom tqdm import tqdm\nimport re\nimport multiprocessing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đường dẫn đến dữ liệu\ntrain_data_path = \"/kaggle/input/legal-document/train.csv\"\ncorpus_path = \"/kaggle/input/legal-document/corpus.csv\"\ntest_data_path = \"/kaggle/input/legal-document/public_test.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm tải dữ liệu Corpus\ndef load_corpus(corpus_path):\n    corpus_df = pd.read_csv(corpus_path)\n    corpus_texts = corpus_df['text'].tolist()\n    corpus_ids = corpus_df['cid'].astype(str).tolist()\n    return corpus_texts, corpus_ids\n\n# Hàm tải dữ liệu huấn luyện\ndef load_training_data(train_data):\n    training_examples = []\n    for index, row in train_data.iterrows():\n        question = row['question']\n        related_contexts = eval(row['context'])  # Dạng list chứa các đoạn văn bản liên quan\n        for context in related_contexts:\n            training_examples.append(InputExample(texts=[question, context]))\n    return training_examples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm fine-tune mô hình Halong Embedding\ndef finetune_halong_embedding(train_data):\n    checkpoint_path = './checkpoint'  # Đường dẫn lưu mô hình\n\n    training_examples = load_training_data(train_data)\n    train_dataloader = DataLoader(training_examples, shuffle=True, batch_size=8)\n    model = SentenceTransformer(\"hiieu/halong_embedding\")\n    \n    # Sử dụng MultipleNegativesRankingLoss cho việc huấn luyện\n    train_loss = losses.MultipleNegativesRankingLoss(model)\n    \n    # Cài đặt thông số huấn luyện\n    num_epochs = 1\n    warmup_steps = int(0.1 * len(train_dataloader) * num_epochs)\n    \n    model.fit(train_objectives=[(train_dataloader, train_loss)],\n              epochs=num_epochs,\n              warmup_steps=warmup_steps,\n              output_path=checkpoint_path)\n    \n    # Kiểm tra nếu checkpoint đã được lưu thành công\n    if os.path.exists(checkpoint_path):\n        print(\"Checkpoint đã được lưu thành công tại:\", checkpoint_path)\n    else:\n        print(\"Lỗi: Không thể lưu checkpoint tại:\", checkpoint_path)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm BM25 truy xuất top_k tài liệu\ndef bm25_retrieve(query, bm25_model, corpus_ids, top_k=10):\n    tokenized_query = query.split()\n    scores = bm25_model.get_scores(tokenized_query)\n    top_k_indices = np.argsort(scores)[::-1][:top_k]\n    top_k_docs = [(corpus_ids[idx], scores[idx]) for idx in top_k_indices]\n    return top_k_docs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm tính toán MRR@10\ndef calculate_mrr(retrieved_results, relevant_cids_list):\n    reciprocal_ranks = []\n    for query_retrieved_docs, relevant_cids in zip(retrieved_results, relevant_cids_list):\n        found = False\n        for rank, (doc_id, _) in enumerate(query_retrieved_docs, start=1):\n            if doc_id in relevant_cids:\n                reciprocal_ranks.append(1 / rank)\n                found = True\n                break\n        if not found:\n            reciprocal_ranks.append(0)\n    return np.mean(reciprocal_ranks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm xếp hạng lại với mô hình đã fine-tune\ndef rerank_with_finetuned_embedding(query, doc_ids, corpus_texts, corpus_ids, model):\n    # Lấy văn bản của các tài liệu\n    documents = [corpus_texts[corpus_ids.index(doc_id)] for doc_id in doc_ids]\n    \n    # Mã hóa câu hỏi và các văn bản\n    query_embedding = model.encode([query], convert_to_tensor=True)\n    doc_embeddings = model.encode(documents, convert_to_tensor=True)\n\n    # Tính độ tương đồng cosine\n    similarities = F.cosine_similarity(query_embedding, doc_embeddings).cpu().numpy()\n    \n    # Xếp hạng các tài liệu\n    sorted_indices = np.argsort(similarities)[::-1]\n    ranked_results = [(doc_ids[idx], similarities[idx]) for idx in sorted_indices]\n    return ranked_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bỏ wandb đi phiền vl\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm khởi tạo cho multiprocessing\ndef init_bm25(tokenized_corpus_, corpus_ids_):\n    global bm25_model, corpus_ids\n    bm25_model = BM25Okapi(tokenized_corpus_)\n    corpus_ids = corpus_ids_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm để trích xuất các số từ chuỗi trong cột 'cid'\ndef parse_cid_list(cid_str):\n    # Sử dụng regex để tìm tất cả các số trong chuỗi\n    numbers = re.findall(r'\\d+', str(cid_str))\n    # Chuyển đổi các số thành chuỗi (vì corpus_ids là danh sách các chuỗi)\n    return [str(num) for num in numbers]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dữ liệu\ncorpus_texts, corpus_ids = load_corpus(corpus_path)\ntrain_df = pd.read_csv(train_data_path)\n\n# Chọn 50 câu hỏi từ tập train để thử nghiệm\ntrain_sample = train_df.sample(n=50, random_state=42).reset_index(drop=True)\n\n# Áp dụng hàm parse_cid_list vào cột 'cid' của mẫu\ntrain_relevant_cids = train_sample['cid'].apply(parse_cid_list).tolist()\ntrain_queries = train_sample['question'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finetuned_model = SentenceTransformer(\"hiieu/halong_embedding\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-tune lại mô hình Halong Embedding\nfinetuned_model = finetune_halong_embedding(train_data_path)\nprint(\"Đã fine-tune mô hình và lưu checkpoint.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chuẩn bị dữ liệu cho BM25\nprint(\"Đang chuẩn bị dữ liệu cho BM25...\")\ntokenized_corpus = [text.split() for text in corpus_texts]\n\n# Sử dụng multiprocessing để truy xuất BM25\nprint(\"Đang thực hiện truy xuất BM25 cho 50 câu hỏi bằng multiprocessing...\")\n\nnum_processes = multiprocessing.cpu_count()  # Số lượng tiến trình, bạn có thể điều chỉnh\nwith multiprocessing.Pool(processes=num_processes, initializer=init_bm25, initargs=(tokenized_corpus, corpus_ids)) as pool:\n    retrieved_results = list(tqdm(pool.imap(bm25_retrieve, train_queries), total=len(train_queries)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tính toán MRR@10 cho 50 câu hỏi với BM25\nmrr_bm25 = calculate_mrr(retrieved_results, train_relevant_cids)\nprint(f\"Chỉ số MRR@10 cho 50 câu hỏi với BM25: {mrr_bm25:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Xếp hạng lại kết quả với mô hình đã fine-tune\nreranked_results = []\nprint(\"Đang xếp hạng lại kết quả với mô hình đã fine-tune...\")\nfor query, retrieved_docs in tqdm(zip(train_queries, retrieved_results), total=len(train_queries), desc=\"Reranking\"):\n    doc_ids = [doc_id for doc_id, _ in retrieved_docs]\n    reranked = rerank_with_finetuned_embedding(query, doc_ids, corpus_texts, corpus_ids, finetuned_model)\n    reranked_results.append(reranked)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tính toán MRR@10 cho 50 câu hỏi sau khi xếp hạng lại\nmrr_finetuned = calculate_mrr(reranked_results, train_relevant_cids)\nprint(f\"Chỉ số MRR@10 cho 50 câu hỏi sau khi fine-tune: {mrr_finetuned:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load dữ liệu\n# corpus_texts, corpus_ids = load_corpus(corpus_path)\n# train_df = pd.read_csv(train_data_path)\n# test_df = pd.read_csv(test_data_path)\n# queries = test_df['question'].tolist()\n# relevant_ids = test_df['qid'].tolist()  # Lấy danh sách id văn bản liên quan từ test\n\n# Phân tích tập dữ liệu Corpus\n# corpus_lengths = pd.Series([len(text.split()) for text in corpus_texts])\n# plt.figure(figsize=(10, 6))\n# sns.histplot(corpus_lengths[corpus_lengths < 1000], bins=50, kde=True)\n# plt.xlabel('Số lượng từ trong văn bản (giới hạn dưới 1000 từ)')\n# plt.ylabel('Tần suất')\n# plt.title('Phân bổ độ dài của các văn bản trong Corpus (Giới hạn dưới 1000 từ)')\n# plt.show()\n\n# # Phân tích tập dữ liệu Train\n# train_question_lengths = train_df['question'].apply(lambda x: len(x.split()))\n# plt.figure(figsize=(10, 6))\n# sns.histplot(train_question_lengths, bins=50, kde=True)\n# plt.xlabel('Số lượng từ trong câu hỏi')\n# plt.ylabel('Tần suất')\n# plt.title('Phân bổ độ dài của câu hỏi trong tập Train')\n# plt.show()\n\n# # Phân tích tập dữ liệu Test\n# test_question_lengths = test_df['question'].apply(lambda x: len(x.split()))\n# plt.figure(figsize=(10, 6))\n# sns.histplot(test_question_lengths, bins=50, kde=True)\n# plt.xlabel('Số lượng từ trong câu hỏi')\n# plt.ylabel('Tần suất')\n# plt.title('Phân bổ độ dài của câu hỏi trong tập Test')\n# plt.show()\n\n# # So sánh phân bổ độ dài câu hỏi giữa tập Train và Test\n# plt.figure(figsize=(12, 6))\n# sns.histplot(train_question_lengths, bins=50, kde=True, color='blue', label='Train')\n# sns.histplot(test_question_lengths, bins=50, kde=True, color='red', label='Test')\n# plt.xlabel('Số lượng từ trong câu hỏi')\n# plt.ylabel('Tần suất')\n# plt.title('So sánh phân bổ độ dài của câu hỏi giữa tập Train và Test')\n# plt.legend()\n# plt.show()\n\n# print(\"Nhận xét:\")\n# print(\"- Số lượng câu hỏi khác nhau trong tập Train và Test cho thấy tính đa dạng và tính tổng quát của mô hình.\")\n# print(\"- Nếu tập Test có nhiều câu hỏi dài hơn so với tập Train, mô hình có thể gặp khó khăn trong việc dự đoán chính xác vì chưa được huấn luyện đầy đủ với những câu hỏi dài như vậy.\")\n# print(\"- Phân bổ độ dài của câu hỏi trong hai tập dữ liệu có thể giúp đánh giá khả năng tổng quát hóa của mô hình.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}